Нагрузочное тестирование.

Нужно заложить время на:
    - разработку методики и профиля (если делает подрядчик, то нужно ходить по разрабам и выяснять подробности, стоит заложить недели 2 для первого раза)
    - разработку заглушек, если они нужны (в зависимости от количества и сложности может быть от 3 дней до 2 недель на заглушку)
    - наполнение БД, если нужно (я бы закладывал 1-2 недели)
    - генерация/селект пулов данных - тоже от объёма зависит, как с наполнением БД)
    - настройка всяческого мониторинга. Базовые метрики настраиваются за день, а вот всякая специфика местная, типа очередей в БД может и несколько дней занять.
    - конечно нужно время на сами тесты, для первого раза стоит неделю на решение проблем заложить, дальше от количества тестов зависит
    - ну и время на подготовку отчётности, если она нужна
    
        Проект подрядчика это обычно начиная от 3х месяцев.
        Я был на проектах, которые больше полугода шли до первых тестов, но это сложные системы были + проблемы с получением доступов, информации от разрабов и Т.Д.
        
Методика
    1) выяснить цели НТ
    2) если есть методика - почитать 
    3) понять какими кейсами тестируется сейчас
        Неплохо бы понять, почему именно этими
        Это обычно выясняется из статистики в бд или в логах
        Может выясниться, что стоит тестировать не только этими, но и другими
        А может какие-то и не нужны
    4) у тех, кто сейчас тестирует взять скрипты и научиться ими пользоваться.
        Если это нереально - придётся делать скрипты самому
    5) протестировать нужными тестами (зависит от целей НТ)
    6) прикинуть, какие могут быть выводы из результатов ваших тестов
    
    
Я так понимаю, что таким образом можно понять примерное соотношение прода к тестовому контуру? Т.е. если мы знаем, что тестовый контур у нас 1/2 от прода. Проведя тесты на 1/2 и на 1/4 от прода мы примерно поймём разницу между 1/2 и 1/4 и тогда в дальнейшем можно будет от этого отталкиваться?
    Скорее нет, нельзя так сказать. Экстраполяция результатов не работает в общем случае
        Примеров масса. Пусть система микросервисная. У нас есть 32 ГБайт ОЗУ на стенде и мы тестируем микросервис на 1,2,3,4 репликах по 8 ГБайт в каждой. И знаем, что на продуктиве 2000 ГБайт ОЗУ
        И вот мы видим, что на 4-х количество обрабатонных заданий больше, чем на 1
        А задания пусть читаются из RabbitMQ или Kafka. А ответы пишутся в PostgreSQL и еще на диск или в S3
        И делаем гипотезу, что на проде можно запустить 100 эксземпляров
        А потом получается, что нельзя. Так как 4 реплики делали 100 подключений к RabbitMQ что уже был его предел, и сделать 5 реплик технически невозможн. 4 реплики делали 200 подключений к PostgreSQL, а у него был предел в 500 подключений, где 300 - подключений другим сервисам. И на проде есть 2000 ГБайт ОЗУ, но все думали что они там есть и все заскейлили свои сервисы в 20 реплик (все 100 команд так сделали) и больше нет там столько
        И получается, что тест показывает только производительность текущей конфигурации. Показывает некоторые ошибки. И растет ли прозводительность при масштабировании или это не работает вообще
        А проблемы будущего он не показывает. И сделать предположения об этих проблемах почти нельзя
    Исключение - тестируемый сервис использует InMemory базу данных. Он не связан ни с каким другим сервисом или источником. Сервис отдает текущую погоду в Москве. А другой погоду в Токио. И это регулируется настройками только - чью погоду он будет отдавать из памяти. И если из Токио будет приходить больше запросов то можно будет поднять больше серверов. Но для этого надо знать сколько RPS держит один сервер при текущих настройках. Какие настройки оптимальны/минимальны. А при необходимости добавлять серверы на проде